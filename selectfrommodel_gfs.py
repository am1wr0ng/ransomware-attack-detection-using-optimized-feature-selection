# -*- coding: utf-8 -*-
"""selectFromModel_GFS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xUDmtIjU-41-d5BIWtSJmRHYT26A_MB6

## Preprocessing
"""

!pip install category_encoders

import numpy as np
import pandas as pd
import time
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

from google.colab import files
uploaded = files.upload()

data = pd.read_csv('전체라벨링랜섬웨어.csv')
print(data.head())

data.columns

from category_encoders import OrdinalEncoder

enc1 = OrdinalEncoder(cols = ['metadata.client_urn', 'metadata.hostname', 'metadata.os',
       'metadata.uname', 'metadata.os_release', 'metadata.os_version',
       'metadata.usernames', 'metadata.mac_address',
       'metadata.deprecated_session_id', 'metadata.source_urn',
       'metadata.hardware_info.serial_number',
       'metadata.hardware_info.system_manufacturer', 'metadata.kernel_version',
       'metadata.cloud_instance_type', 'urn', 'basename', 'st_mode', 'st_ino',
       'st_dev', 'st_nlink', 'st_uid', 'st_gid', 'st_size', 'st_atime',
       'st_mtime', 'st_ctime', 'st_blocks', 'st_blksize', 'st_rdev', 'family',
       'type', 'local_address.ip', 'local_address.port', 'remote_address.ip',
       'remote_address.port', 'state', 'pid', 'ctime'])
data = enc1.fit_transform(data)
data

import numpy as np
import pandas as pd
import time
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""## Data Split"""

data = data.fillna(0)

#컬럼명이 labeling인 부분을 삭제하고, 그걸 X로로
X =  data.drop(labels='labeling',axis=1)
X

#컬럼명이 labeling인 부분을 y (공격/정상을 분류하는 문제이므로로)
y = data['labeling']
y

#데이터셋 스케일링링
from sklearn.preprocessing import StandardScaler

# 변형 객체 생성
std_scaler = StandardScaler()

# 학습데이터의 모수 분포 저장
std_scaler.fit(X)

# 학습 데이터 스케일링
X_train_scaled = std_scaler.transform(X)
X = X_train_scaled

#training set:test set = 7:3비율로 맞춰놓고 학습하기 위함

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state = 42
)

data

data.shape

X_train
#label drop

"""## SelectFromModel"""

from sklearn.ensemble import RandomForestClassifier

#numpy에서 pandas frame으로 변환
X_train = pd.DataFrame(X_train)

feat_labels = X_train.columns

rf = RandomForestClassifier(n_estimators = 1000, random_state = 0, n_jobs = -1)

rf.fit(X_train, y_train)
importances = rf.feature_importances_

indices = np.argsort(rf.feature_importances_)[::-1] 
# np.argsort() : 작은 것 부터 순서대로 뽑아내는 index
# [::-1] 다시 역순으로

labels=[]
for f in range(10):
    print('%2d) %-*s %f' % (f+1, 30, data.columns[feat_labels[indices[f]]+1], importances[indices[f]]))
    labels.append(feat_labels[indices[f]])
    # 순서, 30으로 나누기, 인덱스와 중요도 출력

sfm = SelectFromModel(rf, threshold = 'median', prefit = True)
print('Number of features before selection : {}'.format(X_train.shape[1]))

# sfm 적용
n_features = sfm.transform(X_train).shape[1]

print("feature selection 후 feature 수 : {}". format(n_features))

selected_vars = list(feat_labels[sfm.get_support()])

